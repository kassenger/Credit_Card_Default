{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribute Information:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "default: (Yes = 1, No = 0)\n",
    "\n",
    "limit_bal: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
    "\n",
    "Gender: (1 = male; 2 = female).\n",
    "\n",
    "Education: (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
    "\n",
    "Marriage: (1 = married; 2 = single; 3 = others).\n",
    "\n",
    "Age\n",
    "\n",
    "pay_1 = the repayment status in September, 2005\n",
    "\n",
    "pay_2 = the repayment status in August, 2005\n",
    "\n",
    "pay_3 = the repayment status in July, 2005\n",
    "\n",
    "pay_4 = the repayment status in June, 2005\n",
    "\n",
    "pay_5 = the repayment status in May, 2005\n",
    "\n",
    "pay_6 = the repayment status in April, 2005\n",
    "\n",
    "(-1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.)\n",
    "\n",
    "bill_amt1: amount of bill statement in September, 2005\n",
    "\n",
    "bill_amt2: amount of bill statement in August, 2005\n",
    "\n",
    "bill_amt3: amount of bill statement in July, 2005\n",
    "\n",
    "bill_amt4: amount of bill statement in June, 2005\n",
    "\n",
    "bill_amt5: amount of bill statement in May, 2005\n",
    "\n",
    "bill_amt6: amount of bill statement in April, 2005\n",
    "\n",
    "pay_amt1: amount paid in September, 2005\n",
    "\n",
    "pay_amt2: amount paid in August, 2005\n",
    "\n",
    "pay_amt3: amount paid in July, 2005\n",
    "\n",
    "pay_amt4: amount paid in June, 2005\n",
    "\n",
    "pay_amt5: amount paid in May, 2005\n",
    "\n",
    "pay_amt6: amount paid in April, 2005\n",
    "\n",
    "(NT dollar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:33.507447Z",
     "start_time": "2020-02-12T20:19:33.396982Z"
    }
   },
   "outputs": [],
   "source": [
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:40:48.369363Z",
     "start_time": "2020-02-12T20:40:46.573713Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:40:46.570680Z",
     "start_time": "2020-02-12T20:40:42.251025Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "seed = 69 # Set the random seed for the entire document\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV, ElasticNet, ElasticNetCV\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score, precision_recall_curve\n",
    "from sklearn.metrics import fbeta_score, cohen_kappa_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:42.291299Z",
     "start_time": "2020-02-12T20:19:42.126926Z"
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "import pandas.io.sql as pd_sql\n",
    "# We are also going to do some basic viz\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load File from Sql Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:42.359622Z",
     "start_time": "2020-02-12T20:19:42.296870Z"
    }
   },
   "outputs": [],
   "source": [
    "connection_args = {\n",
    "    'host': 'localhost',  # We are connecting to our _local_ version of psql\n",
    "    'dbname': 'card',    # DB that we are connecting to\n",
    "    'port': 5432 }         \n",
    "connection = pg.connect(**connection_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:43.139911Z",
     "start_time": "2020-02-12T20:19:42.362139Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = 'SELECT * FROM \"credit_card_clients\";'\n",
    "df=pd_sql.read_sql(query, connection)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:43.157132Z",
     "start_time": "2020-02-12T20:19:43.143846Z"
    }
   },
   "outputs": [],
   "source": [
    "# create the header with proper names\n",
    "new_header = df.iloc[0]\n",
    "df = df[1:]\n",
    "df.columns = new_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:43.812956Z",
     "start_time": "2020-02-12T20:19:43.162717Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert the entire dataframe to numeric\n",
    "df = df.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:43.855515Z",
     "start_time": "2020-02-12T20:19:43.818118Z"
    }
   },
   "outputs": [],
   "source": [
    "# change column names\n",
    "df = df.rename(columns={\"SEX\": \"gender\", \"PAY_0\": \"PAY_1\", \"default payment next month\": \"default\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:43.877843Z",
     "start_time": "2020-02-12T20:19:43.860612Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"ID\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:43.898087Z",
     "start_time": "2020-02-12T20:19:43.884056Z"
    }
   },
   "outputs": [],
   "source": [
    "# lowercase the column names\n",
    "df.columns = map(str.lower, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:43.936327Z",
     "start_time": "2020-02-12T20:19:43.910925Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:44.016986Z",
     "start_time": "2020-02-12T20:19:43.945087Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Engineering for Categorical Data\n",
    "## Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:46.027458Z",
     "start_time": "2020-02-12T20:19:46.014744Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_education(num):\n",
    "    \"\"\"\n",
    "    replace the number with the level of education\n",
    "    \"\"\"\n",
    "    if num == 1:\n",
    "        return 'graduate school'\n",
    "    elif num == 2:\n",
    "        return 'university'\n",
    "    elif num == 3:\n",
    "        return 'high school'\n",
    "    else:\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:46.264824Z",
     "start_time": "2020-02-12T20:19:46.242199Z"
    }
   },
   "outputs": [],
   "source": [
    "df.education =  df.education.apply(lambda x: assign_education(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:46.683101Z",
     "start_time": "2020-02-12T20:19:46.439554Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at the distribution of education levels\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.barplot(x=df.education.value_counts().index, y=df.education.value_counts())\n",
    "plt.title('Distribution of Education')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:47.376548Z",
     "start_time": "2020-02-12T20:19:47.358972Z"
    }
   },
   "outputs": [],
   "source": [
    "# set female as 1 and male as 0\n",
    "df['gender'] =  [ 0 if x==1 else 1 for x in df['gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:47.788319Z",
     "start_time": "2020-02-12T20:19:47.577835Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# distribution of gender\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.barplot(x=df.gender.value_counts().index, y=df.gender.value_counts())\n",
    "plt.title('Distribution of Gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marriage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:48.225066Z",
     "start_time": "2020-02-12T20:19:48.214651Z"
    }
   },
   "outputs": [],
   "source": [
    "df['marriage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:48.457353Z",
     "start_time": "2020-02-12T20:19:48.452809Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_marriage(num):\n",
    "    \"\"\"\n",
    "    replace the number with the martial status\n",
    "    \"\"\"\n",
    "    if num == 1:\n",
    "        return 'married'\n",
    "    elif num == 2:\n",
    "        return 'single'\n",
    "    else:\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:49.326690Z",
     "start_time": "2020-02-12T20:19:49.304360Z"
    }
   },
   "outputs": [],
   "source": [
    "df.marriage = df.marriage.apply(lambda x: assign_marriage(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:50.086290Z",
     "start_time": "2020-02-12T20:19:49.846610Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "sns.barplot(x=df.marriage.value_counts().index, y=df.marriage.value_counts())\n",
    "plt.title('Distribution of Marital Status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pay_1, pay_2, pay_3, pay_4, pay_5, pay_6,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:56.451027Z",
     "start_time": "2020-02-12T20:19:52.607408Z"
    }
   },
   "outputs": [],
   "source": [
    "select_df = df[['pay_1','pay_2','pay_3','pay_4','pay_5','pay_6']]\n",
    "\n",
    "count_pay_duly = []\n",
    "for i in range(select_df.shape[0]):\n",
    "    count_pay_duly.append(select_df.iloc[i].tolist().count(-1)) # total count of the payments on time in 6 months\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:56.472039Z",
     "start_time": "2020-02-12T20:19:56.459715Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_pay_i = df.drop(['pay_1','pay_2','pay_3','pay_4','pay_5','pay_6'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:56.496102Z",
     "start_time": "2020-02-12T20:19:56.476057Z"
    }
   },
   "outputs": [],
   "source": [
    "# add count_pay_duly into the df and drop pay_1...\n",
    "df_no_pay_i['count_pay_duly'] = count_pay_duly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:58.720993Z",
     "start_time": "2020-02-12T20:19:58.704451Z"
    }
   },
   "outputs": [],
   "source": [
    "# get dummies of education and marriage\n",
    "ed_dummies = pd.get_dummies(df_no_pay_i.education).drop(['other'], axis = 1)\n",
    "ma_dummies = pd.get_dummies(df_no_pay_i.marriage).drop(['other'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:59.264088Z",
     "start_time": "2020-02-12T20:19:59.244918Z"
    }
   },
   "outputs": [],
   "source": [
    "# set up a new df with all dummies \n",
    "dum_df  = df_no_pay_i.merge(ed_dummies, left_index=True, right_index=True).merge(\n",
    "    ma_dummies, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:19:59.884262Z",
     "start_time": "2020-02-12T20:19:59.868823Z"
    }
   },
   "outputs": [],
   "source": [
    "unordered_df = dum_df.drop(['education', 'marriage'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:20:00.997814Z",
     "start_time": "2020-02-12T20:20:00.987973Z"
    }
   },
   "outputs": [],
   "source": [
    "unordered_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T01:48:30.674600Z",
     "start_time": "2020-02-08T01:48:30.664215Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_df = unordered_df[['gender', 'graduate school', 'high school', 'university',\n",
    "       'married', 'single' , 'age', 'count_pay_duly','limit_bal','bill_amt1',\n",
    "       'bill_amt2', 'bill_amt3', 'bill_amt4', 'bill_amt5', 'bill_amt6',\n",
    "       'pay_amt1', 'pay_amt2', 'pay_amt3', 'pay_amt4', 'pay_amt5', 'pay_amt6','default']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T01:48:31.525011Z",
     "start_time": "2020-02-08T01:48:31.494661Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T01:48:41.797446Z",
     "start_time": "2020-02-08T01:48:41.793484Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T01:48:54.292269Z",
     "start_time": "2020-02-08T01:48:54.273701Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"clean_df.pickle\", \"wb\") as f:\n",
    "    pickle.dump(clean_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:40:55.347787Z",
     "start_time": "2020-02-12T20:40:55.302277Z"
    }
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "### pick up what you left ###\n",
    "#############################\n",
    "\n",
    "with open(\"clean_df.pickle\", \"rb\") as f:\n",
    "    clean_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:33:38.649616Z",
     "start_time": "2020-02-07T05:33:38.638625Z"
    }
   },
   "outputs": [],
   "source": [
    "#%config InlineBackend.figure_format = 'svg'\n",
    "# plt.figure(figsize = (15,8))\n",
    "# ax = sns.heatmap(dum_df.corr(),cmap = \"YlOrRd\",annot = True, vmin = -1, vmax = 1,linewidths = 0.5);\n",
    "# bottom, top = ax.get_ylim()\n",
    "# ax.set_ylim(bottom + 0.5, top - 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T18:53:20.482608Z",
     "start_time": "2020-02-08T18:53:20.231194Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T18:57:39.217509Z",
     "start_time": "2020-02-08T18:57:39.170495Z"
    }
   },
   "outputs": [],
   "source": [
    "Counter(clean_df.default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T18:57:45.845727Z",
     "start_time": "2020-02-08T18:57:45.463445Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import show\n",
    "import seaborn as sns\n",
    "plt.title('Distribution of Credict Card Default')\n",
    "sns.set(style=\"whitegrid\")\n",
    "total = float(len(clean_df.default)) \n",
    "ax = sns.countplot(x= clean_df.default, data=clean_df) # for Seaborn version 0.7 and more\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}'.format(height/total),\n",
    "            ha=\"center\") \n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T18:59:22.195726Z",
     "start_time": "2020-02-08T18:59:22.156150Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_df.corr().iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T18:59:40.556903Z",
     "start_time": "2020-02-08T18:59:40.550210Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T19:01:43.040121Z",
     "start_time": "2020-02-08T19:01:43.013621Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling (no scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:20:16.400452Z",
     "start_time": "2020-02-12T20:20:16.393098Z"
    }
   },
   "outputs": [],
   "source": [
    "# set X and y\n",
    "\n",
    "X = clean_df.iloc[:,:-1]\n",
    "y = clean_df.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T19:04:51.470486Z",
     "start_time": "2020-02-08T19:04:44.178775Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Data splitting for 80% Train/Val and 20% Test \n",
    "X_train_fe, X_test_fe, y_train_val_fe, y_test_fe = train_test_split(X, y, test_size = 0.2, random_state=42) # 20% holdout \n",
    "\n",
    "## This line instantiates the model. \n",
    "rf = RandomForestClassifier() \n",
    "\n",
    "## Fit the model on your training data.\n",
    "rf.fit(X_train_fe.values, y_train_val_fe.values.ravel()) \n",
    "\n",
    "# Obtain the feature importance\n",
    "feature_importance = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index = X_train_fe.columns,\n",
    "                                   columns=['Variable_Importance']).sort_values('Variable_Importance',ascending=True)\n",
    "\n",
    "# Set seaborn contexts \n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "feature_importance.plot.barh(figsize=(15,10))\n",
    "plt.savefig('feature_importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:41:02.470768Z",
     "start_time": "2020-02-12T20:41:02.246959Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn import under_sampling, over_sampling\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from collections import defaultdict\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Hyperparameter Tuning KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:37:59.838904Z",
     "start_time": "2020-02-07T05:37:56.351047Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "scores = cross_val_score(knn, X_smote_train, y_smote_train, cv=10, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:38:02.581689Z",
     "start_time": "2020-02-07T05:38:02.576689Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:39:14.255426Z",
     "start_time": "2020-02-07T05:38:07.241675Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "k_range = [i for i in range(1, 31) if i%2 != 0]\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_smote_train, y_smote_train, cv=10, scoring='recall')\n",
    "    k_scores.append(scores.mean())\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T19:25:38.917533Z",
     "start_time": "2020-02-07T19:25:38.316519Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T23:43:27.372110Z",
     "start_time": "2020-02-06T23:43:27.368911Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# choose k = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision is a good measure to determine, when the costs of False Positive is high. Recall shall be the model metric we use to select our best model when there is a high cost associated with False Negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP: defalut identified as default. we correctly identify the unreliable customes. \n",
    "FP: not default identified as default. Customers who are reliable are identified as default. \n",
    "TN: not default identified as not default. \n",
    "FN: default identified as not default.The cutomers who are reliable are correcly identified. \n",
    "\n",
    "Identifying accurately which customers are most probable to default represents significant business opportunity for all banks.\n",
    "\n",
    "Our clients: banks\n",
    "\n",
    "Recall shall be the model metric we use to select our best model when there is a high cost associated with False Negative.Our obejective is to help the bank identify and take action on customers with high probability of defaulting to improve their bottom line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:41:05.201689Z",
     "start_time": "2020-02-12T20:41:05.191540Z"
    }
   },
   "outputs": [],
   "source": [
    "# set X and y\n",
    "\n",
    "X = clean_df.iloc[:,:-1]\n",
    "y = clean_df.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:41:06.923306Z",
     "start_time": "2020-02-12T20:41:06.916784Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import defaultdict\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:41:07.754449Z",
     "start_time": "2020-02-12T20:41:07.552880Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:42:47.896862Z",
     "start_time": "2020-02-12T20:41:08.198271Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "#collect results for each model\n",
    "cv_results_recall = defaultdict(list) \n",
    "cv_results_precision = defaultdict(list) \n",
    "cv_results_f1 = defaultdict(list) \n",
    "cv_results_accuracy = defaultdict(list) \n",
    "cv_results_fbeta =  defaultdict(list)\n",
    "\n",
    "# generate indies for kf\n",
    "y_train = y_train.values\n",
    "X_train = X_train.values\n",
    "\n",
    "# choose n_neighbors as\n",
    "models = {'Xgboost':XGBClassifier(),\n",
    "          'GNB': GaussianNB(),\n",
    "          'Logistic Regression': LogisticRegression(),\n",
    "          'Random Forest':RandomForestClassifier(),\n",
    "          'Linearsvc': LinearSVC(),\n",
    "          'Knn':KNeighborsClassifier()}\n",
    "          \n",
    "for model_name, model in models.items():\n",
    "    for train_ind, val_ind in kf.split(X_train, y_train):\n",
    "        X_tr, y_tr = X_train[train_ind], y_train[train_ind]\n",
    "    \n",
    "        X_smote_train, y_smote_train = SMOTE(random_state=42).fit_sample(X_tr, y_tr)\n",
    "\n",
    "        X_val,y_val = X_train[val_ind], y_train[val_ind]\n",
    "\n",
    "        model.fit(X_smote_train, y_smote_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # calculate recall score\n",
    "        recall = recall_score(y_val, y_pred) \n",
    "\n",
    "        cv_results_recall[model_name].append(recall)\n",
    "        \n",
    "        # calculate precision score\n",
    "        \n",
    "        precision = precision_score(y_val, y_pred) \n",
    "\n",
    "        cv_results_precision[model_name].append(precision)\n",
    "        \n",
    "        # calculate f1 score\n",
    "        f1 = f1_score(y_val,y_pred)\n",
    "        \n",
    "        cv_results_f1[model_name].append(f1)\n",
    "        \n",
    "        #calculate fbeta score\n",
    "        fbeta = fbeta_score(y_val, y_pred, beta=2)\n",
    "        \n",
    "        cv_results_fbeta[model_name].append(fbeta)\n",
    "        # calculate accuracy\n",
    "        \n",
    "        accuracy = accuracy_score(y_val,y_pred)\n",
    "        \n",
    "        cv_results_accuracy[model_name].append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:42:47.934226Z",
     "start_time": "2020-02-12T20:42:47.902019Z"
    }
   },
   "outputs": [],
   "source": [
    "fbeta_mean = [np.mean(i) for i in cv_results_fbeta.values()]\n",
    "fbeta_var = [np.var(i) for i in cv_results_fbeta.values()]\n",
    "df_cv_fbeta = pd.DataFrame(\n",
    "    {\n",
    "     'fbeta_mean': fbeta_mean,\n",
    "     'fbeta_var': fbeta_var\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:42:48.067577Z",
     "start_time": "2020-02-12T20:42:47.939822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fbeta_mean</th>\n",
       "      <th>fbeta_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.305795</td>\n",
       "      <td>0.000384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.588065</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.390480</td>\n",
       "      <td>0.000838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.285502</td>\n",
       "      <td>0.000330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.454265</td>\n",
       "      <td>0.018755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.453352</td>\n",
       "      <td>0.000091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fbeta_mean  fbeta_var\n",
       "0    0.305795   0.000384\n",
       "1    0.588065   0.000036\n",
       "2    0.390480   0.000838\n",
       "3    0.285502   0.000330\n",
       "4    0.454265   0.018755\n",
       "5    0.453352   0.000091"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_fbeta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:42:48.077943Z",
     "start_time": "2020-02-12T20:42:48.073793Z"
    }
   },
   "outputs": [],
   "source": [
    "model_lst = list(cv_results_recall.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:42:48.087024Z",
     "start_time": "2020-02-12T20:42:48.081300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Xgboost', 'GNB', 'Logistic Regression', 'Random Forest', 'Linearsvc', 'Knn']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T01:36:54.398180Z",
     "start_time": "2020-02-09T01:36:54.382778Z"
    }
   },
   "outputs": [],
   "source": [
    "# the minority class and over-samples it until it is balanced with the majority class.\n",
    "# the model with the best mean score and least amount of variance in performance is chosen\n",
    "\n",
    "model_lst = list(cv_results_recall.keys())\n",
    "recall_mean = [np.mean(i) for i in cv_results_recall.values()]\n",
    "recall_var = [np.var(i) for i in cv_results_recall.values()]\n",
    "df_cv_recall = pd.DataFrame(\n",
    "    {'model_name': model_lst,\n",
    "     'mean': recall_mean,\n",
    "     'variance': recall_var\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T01:37:01.787813Z",
     "start_time": "2020-02-09T01:37:01.752621Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cv_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T02:04:38.421886Z",
     "start_time": "2020-02-09T02:04:38.417172Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'cross validation results for precision score {cv_results_precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T02:09:05.659551Z",
     "start_time": "2020-02-09T02:09:05.651028Z"
    }
   },
   "outputs": [],
   "source": [
    "precision_mean = [np.mean(i) for i in cv_results_precision.values()]\n",
    "precision_var = [np.var(i) for i in cv_results_precision.values()]\n",
    "df_cv_precision = pd.DataFrame(\n",
    "    {'model_name': model_lst,\n",
    "     'mean': precision_mean,\n",
    "     'variance': precision_var\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T04:32:09.873737Z",
     "start_time": "2020-02-09T04:32:09.758702Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cv_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the best model to fit on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:45:09.150867Z",
     "start_time": "2020-02-12T20:45:08.962604Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_best, X_test_best, y_train_best, y_test_best = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:45:10.021969Z",
     "start_time": "2020-02-12T20:45:09.867014Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "X_sm,y_sm = SMOTE(random_state = 42).fit_sample(X_train_best.values, y_train_best.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:46:20.263217Z",
     "start_time": "2020-02-12T20:46:14.679515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2949301267468314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_sm, y_sm)\n",
    "y_predict_xgb = xgb.predict(X_test.as_matrix())\n",
    "print(fbeta_score(y_test.as_matrix(), y_predict_xgb,beta =2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:46:20.324177Z",
     "start_time": "2020-02-12T20:46:20.271228Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5928080885158337\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_sm, y_sm)\n",
    "y_predict_gnb = gnb.predict(X_test)\n",
    "print(fbeta_score(y_test, y_predict_gnb,beta =2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:46:20.698331Z",
     "start_time": "2020-02-12T20:46:20.334513Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3724327451547585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_sm, y_sm)\n",
    "y_predict_lr = lr.predict(X_test)\n",
    "print(fbeta_score(y_test, y_predict_lr,beta =2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:46:28.540228Z",
     "start_time": "2020-02-12T20:46:20.702146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5695426685525695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luyuankong/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_sm, y_sm)\n",
    "y_predict_linear_svc = linear_svc.predict(X_test)\n",
    "print(fbeta_score(y_test, y_predict_linear_svc,beta =2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:46:37.773676Z",
     "start_time": "2020-02-12T20:46:28.543339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2900439954375102\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_sm, y_sm)\n",
    "y_predict_rf = rf.predict(X_test)\n",
    "print(fbeta_score(y_test, y_predict_rf,beta =2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:46:37.781771Z",
     "start_time": "2020-02-12T20:46:37.776799Z"
    }
   },
   "outputs": [],
   "source": [
    "# take a thousnad year to run svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T20:46:38.849735Z",
     "start_time": "2020-02-12T20:46:37.784772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4353459445452189\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_sm, y_sm)\n",
    "y_predict_knn = knn.predict(X_test)\n",
    "print(fbeta_score(y_test, y_predict_knn,beta =2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T05:17:04.128294Z",
     "start_time": "2020-02-09T05:17:02.130984Z"
    }
   },
   "outputs": [],
   "source": [
    "fpr_xgb, tpr_xgb, thresholds_xgb = roc_curve(y_test, xgb.predict_proba(X_test.as_matrix())[:,1])\n",
    "auc_xgb = roc_auc_score(y_test, xgb.predict_proba(X_test.as_matrix())[:, 1]) \n",
    "\n",
    "fpr_gnb, tpr_gnb, thresholds_gnb = roc_curve(y_test, gnb.predict_proba(X_test)[:,1])\n",
    "auc_gnb = roc_auc_score(y_test, gnb.predict_proba(X_test)[:, 1]) \n",
    "\n",
    "fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, lr.predict_proba(X_test)[:,1])\n",
    "auc_lr = roc_auc_score(y_test, lr.predict_proba(X_test)[:, 1]) \n",
    "\n",
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, rf.predict_proba(X_test)[:,1])\n",
    "auc_rf = roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1]) \n",
    "\n",
    "fpr_knn, tpr_knn, thresholds_knn = roc_curve(y_test, knn.predict_proba(X_test)[:,1])\n",
    "auc_knn = roc_auc_score(y_test, knn.predict_proba(X_test)[:, 1]) \n",
    "\n",
    "fpr_lsvc, tpr_lsvc, thresholds_lsvc = roc_curve(y_test, lsvc.predict_proba(X_test)[:,1])\n",
    "auc_lsvc = roc_auc_score(y_test, lsvc.predict_proba(X_test)[:, 1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T07:59:41.360220Z",
     "start_time": "2020-02-07T07:59:40.591083Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(fpr_lr, tpr_lr, lw=1, label='Logistic Regression')\n",
    "plt.plot(fpr_knn, tpr_knn, lw=1, label='KNN')\n",
    "plt.plot(fpr_gnb, tpr_gnb, lw=1, label='Gaussian NB')\n",
    "plt.plot(fpr_rf, tpr_rf, lw=1, label='Random Forest')\n",
    "plt.plot(fpr_xgb, tpr_xgb, lw=1, label='XGBoost')\n",
    "plt.plot(fpr_lsvc, tpr_lsvc, lw=1, label='SVM - Linear')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], c='violet', ls='--')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Model Comparison - ROC curve')\n",
    "plt.legend(ncol=2, fontsize='small')\n",
    "sns.despine()\n",
    "plt.savefig('model_comp_roc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-09T06:28:12.661Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print confusion matrix for Gaussian NB\n",
    "gnb_confusion = confusion_matrix(y_test, gnb.predict(X_test))\n",
    "plt.figure(dpi=150)\n",
    "sns.heatmap(gnb_confusion, cmap=plt.cm.Blues, annot=True,\n",
    "            square=True,\n",
    "           xticklabels=['No Default', 'Default'],\n",
    "           yticklabels=['No Default', 'Default']);\n",
    "\n",
    "b, t = plt.ylim()  # discover the values for bottom and top\n",
    "b += 0.5  # Add 0.5 to the bottom\n",
    "t -= 0.5  # Subtract 0.5 from the top\n",
    "plt.ylim(b, t)  # update the ylim(bottom, top) values\n",
    "\n",
    "plt.xlabel('Prediction', size=15)\n",
    "plt.ylabel('Actual', rotation=0, labelpad=40,size=15)\n",
    "plt.title('GaussianNB confusion matrix');\n",
    "plt.show()\n",
    "plt.savefig('confusion.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "195.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
